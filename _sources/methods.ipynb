{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e404127",
   "metadata": {},
   "source": [
    "# Methods\n",
    "\n",
    "## Datasets\n",
    "<!-- need to revise the demographic information -->\n",
    "\n",
    "We selected two datasets on OpenNeuro for the current analysis: \n",
    "`ds000228` {cite:p}`ds000228:1.1.0` and `ds000030` {cite:p}`ds000030:1.0.0`.\n",
    "Dataset `ds000228` ($N=155$) contains fMRI scans of participants watching a silent version of Pixar animated movie \"Partly Cloudy\". \n",
    "The dataset includes 33 adult subjects \n",
    "($Mean_{age}=24.8$, $SD_{age}=5.3$, $range_{age}: 18-39$; $n_{female}=20$) \n",
    "and 122 children subjects \n",
    "($Mean_{age}=6.7$, $SD_{age}=2.3$, $range_{age}: 3.5-12$; $n_{female}=64$) \n",
    "For more information for the dataset please refers to {cite:t}`richardson_development_2018`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5c476da",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n female: 84.0\n",
      "n female in child: 64.0\n",
      "n female in adult: 20.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full sample</th>\n",
       "      <th>child</th>\n",
       "      <th>adult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>155.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>33.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.555189</td>\n",
       "      <td>6.709461</td>\n",
       "      <td>24.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.071957</td>\n",
       "      <td>2.330938</td>\n",
       "      <td>5.308521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.518138</td>\n",
       "      <td>3.518138</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.300000</td>\n",
       "      <td>4.895210</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.680000</td>\n",
       "      <td>5.980000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.975000</td>\n",
       "      <td>8.397500</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>12.300000</td>\n",
       "      <td>39.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full sample       child      adult\n",
       "count   155.000000  122.000000  33.000000\n",
       "mean     10.555189    6.709461  24.772727\n",
       "std       8.071957    2.330938   5.308521\n",
       "min       3.518138    3.518138  18.000000\n",
       "25%       5.300000    4.895210  21.000000\n",
       "50%       7.680000    5.980000  23.000000\n",
       "75%      10.975000    8.397500  28.000000\n",
       "max      39.000000   12.300000  39.000000"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "ds000228_desc"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from myst_nb import glue\n",
    "\n",
    "from fmriprep_denoise.visualization import tables\n",
    "desc = tables.lazy_report('ds000228')\n",
    "\n",
    "glue(\"ds000228_desc\", desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ee4fd2",
   "metadata": {},
   "source": [
    "Dataset `ds000030` includes multiple tasks collected on subjects of a variety of neuropsychiatric diagnostics, including ADHD, bipolar disorder, schizophrenia , and healthy controls. \n",
    "The current analysis only focused on the resting state scans.\n",
    "Scans with an instrumental artifact (flagged under column `ghost_NoGhost` in `particiapnts.tsv`) were excluded from the analysis pipeline.\n",
    "259 out of 272 subjects of were included in the benchmark. \n",
    "The demographic information per condition is in the following table.\n",
    "\n",
    "|                 | Full sample | Healthy control | Schizophrenia | Bipolar disorder |     ADHD    |\n",
    "|----------------:|------------:|----------------:|--------------:|-----------------:|------------:|\n",
    "|       N(female) |    259(108) |         120(56) |        50(12) |           49(21) |      40(19) |\n",
    "| Age Mean(s.d.)  |   33.3(9.3) |      31.7 (8.8) |    36.5 (8.9) |       35.3 (9.0) | 32.1 (10.4) |\n",
    "|       Age Range |      21--50 |          21--50 |        22--49 |           21--50 |      21--50 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a10fcac",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n female: 108.0\n",
      "n female in ADHD: 19.0\n",
      "n female in BIPOLAR: 21.0\n",
      "n female in SCHZ: 12.0\n",
      "n female in CONTROL: 56.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full sample</th>\n",
       "      <th>ADHD</th>\n",
       "      <th>BIPOLAR</th>\n",
       "      <th>SCHZ</th>\n",
       "      <th>CONTROL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>259.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>120.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.347490</td>\n",
       "      <td>32.050000</td>\n",
       "      <td>35.285714</td>\n",
       "      <td>36.460000</td>\n",
       "      <td>31.691667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.305064</td>\n",
       "      <td>10.409439</td>\n",
       "      <td>9.027735</td>\n",
       "      <td>8.878339</td>\n",
       "      <td>8.827760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>23.750000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>28.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>39.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       full sample       ADHD    BIPOLAR       SCHZ     CONTROL\n",
       "count   259.000000  40.000000  49.000000  50.000000  120.000000\n",
       "mean     33.347490  32.050000  35.285714  36.460000   31.691667\n",
       "std       9.305064  10.409439   9.027735   8.878339    8.827760\n",
       "min      21.000000  21.000000  21.000000  22.000000   21.000000\n",
       "25%      25.000000  23.750000  26.000000  29.000000   24.000000\n",
       "50%      32.000000  28.000000  36.000000  37.500000   28.500000\n",
       "75%      41.000000  40.000000  43.000000  43.750000   39.250000\n",
       "max      50.000000  50.000000  50.000000  49.000000   50.000000"
      ]
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "",
       "name": "ds000030_desc"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "from myst_nb import glue\n",
    "\n",
    "from fmriprep_denoise.visualization import tables\n",
    "desc = tables.lazy_report('ds000030')\n",
    "\n",
    "glue(\"ds000030_desc\", desc) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b4b872",
   "metadata": {},
   "source": [
    "## fMRI data preprocessing\n",
    "\n",
    "We preprocessed with fMRIPrep LTS20.2.1 through [`fMRIPrep-slurm`](https://github.com/SIMEXP/fmriprep-slurm) with the following options:\n",
    "```\n",
    "--use-aroma \\\n",
    "--omp-nthreads 1 \\\n",
    "--nprocs 1 \\\n",
    "--random-seed 0  \\\n",
    "--output-spaces MNI152NLin2009cAsym MNI152NLin6Asym \\\n",
    "--output-layout bids \\\n",
    "--notrack \\\n",
    "--skip_bids_validation \\\n",
    "--write-graph \\\n",
    "--omp-nthreads 1 \\\n",
    "--nprocs 1 \\\n",
    "--resource-monitor\n",
    "```\n",
    "\n",
    "For the full description generated by fMRIPrep, please see [supplemental material](./CITATION.md). \n",
    "\n",
    "## Time series extraction and connectome generation\n",
    "\n",
    "We extract time series with regions of interest (ROI) defined by the following atlases:\n",
    "Gordon atlas {cite:p}`gordon_atlas_2014`, \n",
    "Schaefer 7 network atlas {cite:p}`schaefer_local-global_2017`, \n",
    "Multiresolution Intrinsic Segmentation Template (MIST) {cite:p}`urchs_mist_2019`,\n",
    "and Dictionary of Functional Modes (DiFuMo){cite:p}`difumo_2020`.\n",
    "All atlases were resampled to the resolution of the preprocessed functional data.\n",
    "\n",
    "Further ROI extraction was done on DiFuMo and MIST, \n",
    "because area under the same label can be networks with disjointed regions.\n",
    "We present the labels with the original number of parcel, \n",
    "and denote the number of extracted ROI in brackets. \n",
    "Gordon and Schaefer atlas both comes with parcels as isolated ROI hence were applied as it is in the extraction.\n",
    "Schaefer 1000 parcels atlas was excluded as some regions would be dropped after resampling. \n",
    "\n",
    "- Gordon atlas: 333 \n",
    "- Schaefer atlas: 100, 200, 300, 400, 500, 600, 800[^1]\n",
    "- Multiresolution Intrinsic Segmentation Template (MIST) {cite:p}`urchs_mist_2019`: 7, 12, 20, 36, 64, 122, 197, 325, 444, \"ROI\" (210 parcels, 122 split by the midline)\n",
    "- DiFuMo atlas {cite:p}`difumo_2020`: 64 (114), 128 (200), 256 (372), 512 (637), 1024 (1158)\n",
    "\n",
    "Process involved here are implemented through nilearn {cite:p}`nilearn_2014`.\n",
    "Time series were extracted using `nilearn.maskers.NiftiLabelsMasker` and `nilearn.maskers.NiftiMapsMasker`. \n",
    "Connectomes were calculated using Pearson's Correlations, implemented through `nilearn.connectome.ConnectivityMeasure`.\n",
    "\n",
    "## Confound regression strategies\n",
    "\n",
    "Confound variables were retrieved using API \n",
    "`nilearn.interfaces.fmriprep.load_confounds` (simplified as `load_confounds`), \n",
    "the basic API that retrieves different classes of confound regressor, \n",
    "and `nilearn.interfaces.fmriprep.load_confounds_strategy`(simplified as `load_confounds_strategy`),\n",
    "a higher level wrapper to implement common strategies from the denoising literature.\n",
    "The current section describes the logic behind the design of API.\n",
    "For documentation of the actual function, please see the latest version of `nilearn`. \n",
    "\n",
    "### Basic noise components\n",
    "\n",
    "To enable easy confound variables loading from fMRIPrep outputs, \n",
    "`load_confounds` provides an interface that groups subsets of confound variables into noise components and their parameters. \n",
    "It is possible to fine-tune a subset of noise components and their parameters through this function.\n",
    "The implementation will only support fMRIPrep functional derivative directory from the 1.2.x series. The compcor noise component requires 1.4.x series or above.\n",
    "\n",
    "<!-- Explain the logic of nilearn API mirror the intro -->\n",
    "Two types of regressors are always loaded with no additional parameters for user customisation:\n",
    "\n",
    "- `high_pass`: discrete cosines transformation basis regressors to handle low-frequency signal drifts.\n",
    "- `non_steady_state` denotes volumes collected before the fMRI scanner has reached a stable state.\n",
    "\n",
    "`motion`, `wm_csf`, and `global_signal` shares similar expansion options:\n",
    "\n",
    "- `motion`: head motion estimates translation/rotation (6 parameters).\n",
    "- `wm_csf`: average signal extracted from masks of white matter and cerebrospinal fluids (2 parameters).\n",
    "- `global_signal`: average signal extracted from brain mask (1 parameters).\n",
    "\n",
    "For these three parameters above, user can select from the following four options:\n",
    "- `basic`: just the original signal (n parameter)\n",
    "- `power2`: original signal and quadratic term (2 * n parameters)\n",
    "- `derivatives`: original signal and temporal derivative (2 * n parameters)\n",
    "- `full`:  original signal + temporal derivatives + quadratic terms + quadratic terms temporal derivatives (4 * n parameters)\n",
    "\n",
    "\n",
    "`scrub` generates mask to exclude volumes with excessive motion {cite:p}`power_scrubbing_2012`. \n",
    "Two types of parameters can be used to determined volumes to be excluded.\n",
    "- `fd_threshold`: set the head motion cut-off value determined by framewise displacement approach {cite:p}`power_scrubbing_2012`.\n",
    "- `std_dvars_threshold`: set the head motion cut-off value determined by the standard deviation of root mean square approach {cite:p}`power_scrubbing_2012,jenkinson_2002`.\n",
    "\n",
    "The CompCor {cite:p}`behzadi_compcor_2007` approach has two associated parameters \n",
    "- `compcor` allows users to select components generated by the temporal approach, \n",
    "    or the anatomical approach with specific details for the mask used in noise signal extraction.\n",
    "- `n_compcor` retrieves the number of principle components to retrieve. \n",
    "\n",
    "For the ICA-based approach, fMRIPrep implemented ICA-AROMA {cite:p}`aroma`. \n",
    "User must manually enable ICA-AROMA with flag `--use-aroma` when using fMRIPrep.\n",
    "The parameter `ica_aroma` allows two approaches: \n",
    "1. Use fMRIPrep output with suffix `desc-smoothAROMAnonaggr_bold.nii.gz`.\n",
    "2. Use noise independent components only. Must be used with output with suffix `desc-preproc_bold.nii.gz`.\n",
    "\n",
    "### Pre-defined strategies\n",
    "\n",
    "`load_confounds_strategy` provides an interface to select confounds based on past literature with limited parameters for user customisation: \n",
    "`simple` {cite:p}`fox_pnas_2005` (motion parameters, and tissue signal), \n",
    "`scrubbing` {cite:p}`power_scrubbing_2012`(volume censoring, motion parameters, and tissue signal),\n",
    "`compcor` {cite:p}`behzadi_compcor_2007`(anatomical compcor and motion parameters),\n",
    "and `aroma` {cite:p}`aroma`(ICA-AROMA based denoising, and tissue signal).\n",
    "All strategies but `compcor` provides an option to add global signal to the confound regressors.\n",
    "\n",
    "### Examined strategies\n",
    "\n",
    "We evaluated common confound regression strategies that are possible through fMRIPrep generated confound regressors. \n",
    "Subjects with high motion, indicated by less than 80% of remaining volumes after scrubbing with a 0.5 mm threshold, were excluded from all analysis. \n",
    "The connectome generated from high-pass filtered time series were served as a comparison baseline.\n",
    "Confound variables were accessed using API `load_confounds_strategy`.\n",
    "The detailed 11 strategies and a full breakdown of parameters used under the hood is presented in the table below.\n",
    "\n",
    "| strategy        | image                          | `high_pass` | `motion` | `wm_csf` | `global_signal` | `scrub` | `fd_thresh` | `compcor`       | `n_compcor` | `ica_aroma` | `demean` |\n",
    "|-----------------|--------------------------------|-------------|----------|----------|-----------------|---------|-------------|-----------------|-------------|-------------|----------|\n",
    "| baseline        | `desc-preproc_bold`            | `True`      | N/A      | N/A      | N/A             | N/A     | N/A         | N/A             | N/A         | N/A         | `True`   |\n",
    "| simple          | `desc-preproc_bold`            | `True`      | `full`   | `basic`  | N/A             | N/A     | N/A         | N/A             | N/A         | N/A         | `True`   |\n",
    "| simple+gsr      | `desc-preproc_bold`            | `True`      | `full`   | `basic`  | `basic`         | N/A     | N/A         | N/A             | N/A         | N/A         | `True`   |\n",
    "| scrubbing.5     | `desc-preproc_bold`            | `True`      | `full`   | `full`   | N/A             | `5`     | `0.5`       | N/A             | N/A         | N/A         | `True`   |\n",
    "| scrubbing.5+gsr | `desc-preproc_bold`            | `True`      | `full`   | `full`   | `basic`         | `5`     | `0.5`       | N/A             | N/A         | N/A         | `True`   |\n",
    "| scrubbing.2     | `desc-preproc_bold`            | `True`      | `full`   | `full`   | N/A             | `5`     | `0.2`       | N/A             | N/A         | N/A         | `True`   |\n",
    "| scrubbing.2+gsr | `desc-preproc_bold`            | `True`      | `full`   | `full`   | `basic`         | `5`     | `0.2`       | N/A             | N/A         | N/A         | `True`   |\n",
    "| compcor         | `desc-preproc_bold`            | `True`      | `full`   | N/A      | N/A             | N/A     | N/A         | `anat_combined` | `all`       | N/A         | `True`   |\n",
    "| compcor6        | `desc-preproc_bold`            | `True`      | `full`   | N/A      | N/A             | N/A     | N/A         | `anat_combined` | `6 `        | N/A         | `True`   |\n",
    "| aroma           | `desc-smoothAROMAnonaggr_bold` | `True`      | N/A      | `basic`  | N/A             | N/A     | N/A         | N/A             | N/A         | `full`      | `True`   |\n",
    "| aroma+gsr       | `desc-smoothAROMAnonaggr_bold` | `True`      | N/A      | `basic`  | `basic`         | N/A     | N/A         | N/A             | N/A         | `full`      | `True`   |\n",
    "\n",
    "## Denoising evaluation measures\n",
    "\n",
    "We used three metrics {cite:p}`ciric_benchmarking_2017`, {cite:p}`parkes_evaluation_2018` described in the previous literature to evaluate the denoising results. \n",
    "Motion related metrics are centred around framewise displacement.\n",
    "Framewise displacement (FD) indexes the movement of the head from one volume to the next.\n",
    "The movement includes the transitions on the three axes ($x$, $y$, $z$) and the respective rotation ($\\alpha$, $\\beta_t$, $\\gamma$).\n",
    "Rotational displacements are calculated as the displacement on the surface of a sphere of radius 50 mm {cite}`power_scrubbing_2012`.\n",
    "fMRIPrep genetates the FD based on the formula proposed in {cite}`power_scrubbing_2012`.\n",
    "The FD at each time point $t$ is expressed as:\n",
    "\n",
    "$$\n",
    "\\text{FD}_t = |\\Delta d_{x,t}| + |\\Delta d_{y,t}| +\n",
    "|\\Delta d_{z,t}| + |\\Delta \\alpha_t| + |\\Delta \\beta_t| + |\\Delta \\gamma_t|\n",
    "$$\n",
    "\n",
    "The details of each measures are explained as followed.\n",
    "\n",
    "### Quality control / functional connectivity (QC-FC)\n",
    "\n",
    "QC-FC {cite:p}`power_recent_2015` quantifies the correlation between mean FD and functional connectivity.\n",
    "This is calculated by a partial correlation between mean FD and connectivity with age and sex as covariates. \n",
    "The denoising methods should aim to reduce the QC-FC value.\n",
    "The significants values reported are control for multiple comparisons with false positive rate correction.\n",
    "\n",
    "### Distance-dependent effects of motion on connectivity \n",
    "\n",
    "To determine the residual distance-dependence of subject movement, \n",
    "we first calculate the Euclidean distance between the centers of mass of ecah pair of parcels {cite:p}`power_scrubbing_2012`. \n",
    "We then correlated the distance separating each pair of parcels and the associated QC-FC correlation of the edge connecting those parcels.\n",
    "Closer parcels generally exhibiting greater impact of motion on connectivity. \n",
    "We expect to see a general trend of negative correlation to no correlation after confound regression.\n",
    "\n",
    "### Network modularity \n",
    "\n",
    "Confound regressors has the potential to remove real signal in addition to motion-related noise. \n",
    "In order to evaluate this possibility, we computed modularity quality, \n",
    "an explicit quantification of the degree to which there are structured sub-networks in a given network, \n",
    "in this case the de-noised connectome {cite:p}`satterthwaite_impact_2012`.\n",
    "Modularity quality is quantified by graph community detection based on Louvain method {cite:p}`rubinov2010`,\n",
    "implemented in the Brain Connectome Toolbox.\n",
    "If confound regression and censoring were removing real signal in addition to motion-related noise, \n",
    "we expect that modularity would decline.\n",
    "To understand the extend of correlation between modularity and motion. \n",
    "we computed the partial correlation between subjects' modularity values and mean FD, \n",
    "with age and sex as covariates. \n",
    "\n",
    "[^1]: When resampling 1000 parcel version of the Schaefer atlas to match the preprocessed data, \n",
    "some subjects will miss a parcel."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md:myst",
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.5"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "source_map": [
   13,
   30,
   42,
   57,
   69
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}